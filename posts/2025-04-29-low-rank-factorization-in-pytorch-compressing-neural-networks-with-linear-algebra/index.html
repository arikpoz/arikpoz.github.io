<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Low-Rank Factorization in PyTorch: Compressing Neural Networks with Linear Algebra | Practical ML</title>
<meta name="keywords" content="machine-learning, optimization, deep-learning, low-rank-factorization, pytorch, model-compression">
<meta name="description" content="
Introduction
Can we shrink neural networks without sacrificing much accuracy?
Low-rank factorization is a powerful, often overlooked technique that compresses models by decomposing large weight matrices into smaller components.
In this post, we&rsquo;ll explain what low-rank factorization is, show how to apply it to a ResNet50 model in PyTorch, and evaluate the trade-offs.">
<meta name="author" content="Arik Poznanski">
<link rel="canonical" href="https://arikpoz.github.io/posts/2025-04-29-low-rank-factorization-in-pytorch-compressing-neural-networks-with-linear-algebra/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.f49d66caae9ea0fd43f21f29e71a8d3e284517ed770f2aa86fa012953ad3c9ef.css" integrity="sha256-9J1myq6eoP1D8h8p5xqNPihFF&#43;13Dyqob6ASlTrTye8=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://arikpoz.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://arikpoz.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://arikpoz.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://arikpoz.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://arikpoz.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://arikpoz.github.io/posts/2025-04-29-low-rank-factorization-in-pytorch-compressing-neural-networks-with-linear-algebra/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<meta name="google-site-verification" content="W9Zr2fU6GN7Pj5eoP80QHjzCMltqYsT_ut_zg5S8FP8" />


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body, {delimiters: [{left: '$$', right: '$$', display: true},{left: '$', right: '$', display: false}]});">
</script>

      <script async src="https://www.googletagmanager.com/gtag/js?id=G-KDV9XDG1TJ"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-KDV9XDG1TJ');
        }
      </script>



</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://arikpoz.github.io/" accesskey="h" title="Practical ML (Alt + H)">Practical ML</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://arikpoz.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://arikpoz.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://arikpoz.github.io/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      Low-Rank Factorization in PyTorch: Compressing Neural Networks with Linear Algebra
    </h1>
    <div class="post-meta"><span title='2025-04-29 00:00:00 +0000 UTC'>April 29, 2025</span>&nbsp;·&nbsp;12 min&nbsp;·&nbsp;Arik Poznanski

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#introduction" aria-label="Introduction">Introduction</a></li>
                <li>
                    <a href="#what-is-low-rank-factorization" aria-label="What Is Low-Rank Factorization?">What Is Low-Rank Factorization?</a></li>
                <li>
                    <a href="#where-can-we-apply-it" aria-label="Where Can We Apply It?">Where Can We Apply It?</a></li>
                <li>
                    <a href="#pytorch-example-applying-low-rank-factorization-to-resnet50" aria-label="PyTorch Example: Applying Low-Rank Factorization to ResNet50">PyTorch Example: Applying Low-Rank Factorization to ResNet50</a><ul>
                        
                <li>
                    <a href="#training-baseline-model" aria-label="Training Baseline Model">Training Baseline Model</a></li>
                <li>
                    <a href="#training-helper-functions" aria-label="Training Helper Functions">Training Helper Functions</a></li>
                <li>
                    <a href="#low-rank-factorization" aria-label="Low-Rank Factorization">Low-Rank Factorization</a></li>
                <li>
                    <a href="#exploring-the-impact-of-epsilon-on-compression-and-performance" aria-label="Exploring the Impact of Epsilon on Compression and Performance">Exploring the Impact of Epsilon on Compression and Performance</a></li></ul>
                </li>
                <li>
                    <a href="#results" aria-label="Results">Results</a></li>
                <li>
                    <a href="#when-it-works-and-when-it-doesnt" aria-label="When It Works, and When It Doesn’t">When It Works, and When It Doesn’t</a></li>
                <li>
                    <a href="#combining-with-other-techniques" aria-label="Combining with Other Techniques">Combining with Other Techniques</a></li>
                <li>
                    <a href="#summary" aria-label="Summary">Summary</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p><img alt="&ldquo;Diagram of low-rank factorization compressing ResNet50, showing 93% size reduction, 10% lower latency, and 3.5% accuracy drop.&rdquo;" loading="lazy" src="/posts/2025-04-29-low-rank-factorization-in-pytorch-compressing-neural-networks-with-linear-algebra/lead-image.jpg"></p>
<h2 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h2>
<p>Can we shrink neural networks without sacrificing much accuracy?
Low-rank factorization is a powerful, often overlooked technique that compresses models by decomposing large weight matrices into smaller components.</p>
<p>In this post, we&rsquo;ll explain what low-rank factorization is, show how to apply it to a ResNet50 model in PyTorch, and evaluate the trade-offs.</p>
<p>In our example, we achieved a <strong>93% reduction in model size</strong> (from 94.38 MB down to 6.9 MB), <strong>cut inference latency by 10%</strong>, and <strong>incurred only a 3.5% drop in accuracy</strong>, a compelling trade-off for many practical applications!</p>
<hr>
<h2 id="what-is-low-rank-factorization">What Is Low-Rank Factorization?<a hidden class="anchor" aria-hidden="true" href="#what-is-low-rank-factorization">#</a></h2>
<p>Low-rank factorization refers to the process of approximating a matrix with the product of two smaller matrices. If a weight matrix <code>W</code> has shape <code>(m, n)</code> and approximate rank <code>r</code>, we can write:</p>
<p>$$
W ≈ U \cdot V
$$
where $$
U ∈ R^{m×r} , V ∈ R^{r×n}
$$</p>
<p>This decomposition reduces the number of parameters from <code>m*n</code> to <code>r*(m + n)</code>, which is a big win if <code>r &lt;&lt; min(m, n)</code>.</p>
<p><img alt="&ldquo;An n by m matrix, factored to , n by r and r by m matrices.&rdquo;" loading="lazy" src="/posts/2025-04-29-low-rank-factorization-in-pytorch-compressing-neural-networks-with-linear-algebra/low-rank-factorization.jpg"></p>
<p>In deep learning, many weight matrices, especially in linear and convolutional layers, are highly redundant and can be approximated well by low-rank versions. This insight is closely tied to the idea that neural networks overparameterize, and that some of this redundancy can be removed with minimal accuracy loss.</p>
<p>Low-rank factorization is typically achieved by applying <strong>Singular Value Decomposition (SVD)</strong> to the weight matrix. SVD decomposes a matrix into three components, <code>U</code>, <code>S</code>, and <code>Vᵀ</code>, capturing its principal components. By keeping only the top singular values and corresponding vectors, we can approximate the original matrix with lower rank while preserving most of its information.</p>
<p>However, after factorization, the model usually suffers a drop in accuracy. Fine-tuning the compressed model is typically required to regain most of the original performance.</p>
<hr>
<h2 id="where-can-we-apply-it">Where Can We Apply It?<a hidden class="anchor" aria-hidden="true" href="#where-can-we-apply-it">#</a></h2>
<p>Low-rank factorization is most applicable in the following cases:</p>
<ul>
<li>
<p><strong>Fully connected layers</strong>: These are easiest to factorize, since their weights are already 2D matrices.</p>
</li>
<li>
<p><strong>Convolutional layers</strong>: These need to be reshaped to 2D first (e.g., <code>[out_channels, in_channels * kernel_h * kernel_w]</code>), then factored, then reshaped back into two sequential convolutional layers.</p>
</li>
<li>
<p><strong>Embedding layers</strong>: Can also benefit from factorization in NLP tasks.</p>
</li>
</ul>
<p>It works best on larger layers with high-dimensional weight matrices. You can often skip very small layers or those with strong structural constraints.</p>
<p>Heuristics for where to apply:</p>
<ul>
<li>Start with the largest layers, typically toward the end of the model</li>
<li>Use the SVD spectrum to decide which layers are compressible, a steep drop-off in singular values suggests high redundancy</li>
</ul>
<hr>
<h2 id="pytorch-example-applying-low-rank-factorization-to-resnet50">PyTorch Example: Applying Low-Rank Factorization to ResNet50<a hidden class="anchor" aria-hidden="true" href="#pytorch-example-applying-low-rank-factorization-to-resnet50">#</a></h2>
<p>In this section, we will apply low-rank factorization to a ResNet50 baseline model, trained on CIFAR-10. We will use various compression ratio to evaluate the accuracy-size-latency trade-offs.</p>
<p>For a complete Jupyter notebook implementation, visit <a href="https://github.com/arikpoz/neural-network-optimization/blob/main/Low%20Rank%20Factorization.ipynb">this link</a>. I also added a <a href="https://github.com/arikpoz/neural-network-optimization/blob/main/utils.ipynb">utils notebook</a> to keep some commonly used functions. Both are part of my <a href="https://github.com/arikpoz/neural-network-optimization">Neural Network Optimization</a> GitHub repository.</p>
<h3 id="training-baseline-model">Training Baseline Model<a hidden class="anchor" aria-hidden="true" href="#training-baseline-model">#</a></h3>
<p>The code below begins by adapting and training a ResNet50 model on the CIFAR-10 dataset to establish a strong baseline. To maximize the accuracy of both the baseline model and the fine-tuned compressed models, I have enhanced the <code>train</code> function with several advanced features:</p>
<ul>
<li><strong>Learning Rate Scheduling</strong>: Automatically reduces the learning rate when the validation loss plateaus.</li>
<li><strong>Early Stopping</strong>: Halts training when the validation loss stops improving, preventing overfitting.</li>
<li><strong>Model Checkpointing</strong>: Saves the best-performing model during training for later use.</li>
<li><strong>Gradient Clipping</strong>: Mitigates the risk of exploding gradients by capping the gradient values during backpropagation.</li>
</ul>
<p>These improvements ensure a robust training process, yielding optimal results for both the original and compressed models.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">device</span> <span class="o">=</span> <span class="n">get_device</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">test_loader</span> <span class="o">=</span> <span class="n">get_cifar10_loaders</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">get_resnet50_for_cifar10</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">train</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_loader</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">val_loader</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">optimizer</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">criterion</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">device</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">grad_clip</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">save_path</span><span class="o">=</span><span class="s2">&#34;full_model_resnet50_best_model.pt&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">early_stopping_patience</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">resume</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></div><h3 id="training-helper-functions">Training Helper Functions<a hidden class="anchor" aria-hidden="true" href="#training-helper-functions">#</a></h3>
<blockquote>
<p><strong>Note</strong>: To facilitate reuse and maintain clarity, the commonly used functions have been relocated to a dedicated <a href="https://github.com/arikpoz/neural-network-optimization/blob/main/utils.ipynb">utils notebook</a>. They are included here for reference and completeness.</p></blockquote>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">get_device</span><span class="p">(</span><span class="n">silent</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    Returns the device to be used for PyTorch operations.
</span></span></span><span class="line"><span class="cl"><span class="s2">    If a GPU is available, it returns &#39;cuda&#39;, otherwise it returns &#39;cpu&#39;.
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&#34;cuda&#34;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&#34;cpu&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Using device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">device</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">get_cifar10_loaders</span><span class="p">(</span><span class="n">train_ratio</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">train_batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">test_batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    Returns the CIFAR-10 dataset loaders for training, validation and testing.
</span></span></span><span class="line"><span class="cl"><span class="s2">    The training set is shuffled, while the test set is not.
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">    reference: Learning Multiple Layers of Features from Tiny Images, Alex Krizhevsky, 2009.
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># define transform for CIFAR-10 dataset</span>
</span></span><span class="line"><span class="cl">    <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.49139968</span><span class="p">,</span> <span class="mf">0.48215827</span><span class="p">,</span> <span class="mf">0.44653124</span><span class="p">],</span>  <span class="c1"># CIFAR-10 means</span>
</span></span><span class="line"><span class="cl">                             <span class="n">std</span>  <span class="o">=</span> <span class="p">[</span><span class="mf">0.24703233</span><span class="p">,</span> <span class="mf">0.24348505</span><span class="p">,</span> <span class="mf">0.26158768</span><span class="p">])</span>  <span class="c1"># CIFAR-10 stds</span>
</span></span><span class="line"><span class="cl">    <span class="p">])</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">    <span class="c1"># load full CIFAR-10 train set</span>
</span></span><span class="line"><span class="cl">    <span class="n">full_trainset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># calculate split sizes for train and validation sets</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">train_ratio</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">full_trainset</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">val_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">full_trainset</span><span class="p">)</span> <span class="o">-</span> <span class="n">train_size</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># perform split</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_subset</span><span class="p">,</span> <span class="n">val_subset</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="n">full_trainset</span><span class="p">,</span> <span class="p">[</span><span class="n">train_size</span><span class="p">,</span> <span class="n">val_size</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">    <span class="c1"># create DataLoaders</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_subset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">train_batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_subset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">train_batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># CIFAR-10 test set and loader for accuracy evaluation</span>
</span></span><span class="line"><span class="cl">    <span class="n">test_set</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">test_batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Full train set size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">full_trainset</span><span class="p">)</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Train ratio: </span><span class="si">{</span><span class="n">train_ratio</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Train samples: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_subset</span><span class="p">)</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Validation samples: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">val_subset</span><span class="p">)</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Test samples: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_set</span><span class="p">)</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Number of training batches: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Number of validation batches: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="p">)</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Number of test batches: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">test_loader</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">get_resnet50_for_cifar10</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    Returns a modified ResNet-50 model for CIFAR-10 classification.
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">device</span> <span class="o">=</span> <span class="n">get_device</span><span class="p">(</span><span class="n">silent</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet50</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">maxpool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">train</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_loader</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">val_loader</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">optimizer</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">criterion</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">device</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">epochs</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">scheduler</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">grad_clip</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">save_path</span><span class="o">=</span><span class="s2">&#34;best_model.pt&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">early_stopping_patience</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">resume</span><span class="o">=</span><span class="kc">True</span>
</span></span><span class="line"><span class="cl"><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    Trains the model using the provided data loaders, optimizer, and loss function.
</span></span></span><span class="line"><span class="cl"><span class="s2">    Supports early stopping and model checkpointing.
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">start_epoch</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="n">best_val_loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&#34;inf&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">epochs_without_improvement</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Optional resume</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">resume</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">save_path</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">save_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s2">&#34;model_state&#34;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s2">&#34;optimizer_state&#34;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="s2">&#34;scheduler_state&#34;</span> <span class="ow">in</span> <span class="n">checkpoint</span> <span class="ow">and</span> <span class="n">scheduler</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">scheduler</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s2">&#34;scheduler_state&#34;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="n">best_val_loss</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&#34;best_val_loss&#34;</span><span class="p">,</span> <span class="n">best_val_loss</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">start_epoch</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&#34;epoch&#34;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;🔁 Resumed training from epoch </span><span class="si">{</span><span class="n">start_epoch</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_epoch</span><span class="p">,</span> <span class="n">epochs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
</span></span><span class="line"><span class="cl">        <span class="n">total_correct</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">        <span class="n">total_samples</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">train_loop</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">&#34;[Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">]&#34;</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="ow">in</span> <span class="n">train_loop</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">grad_clip</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">grad_clip</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">preds</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">total_correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">preds</span> <span class="o">==</span> <span class="n">targets</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">total_samples</span> <span class="o">+=</span> <span class="n">targets</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">avg_train_loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">train_accuracy</span> <span class="o">=</span> <span class="n">total_correct</span> <span class="o">/</span> <span class="n">total_samples</span>
</span></span><span class="line"><span class="cl">        <span class="n">tqdm</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Epoch </span><span class="si">{</span><span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="si">:</span><span class="s2">&gt;3</span><span class="si">}</span><span class="s2"> | Train Loss: </span><span class="si">{</span><span class="n">avg_train_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> | Acc: </span><span class="si">{</span><span class="n">train_accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Validation</span>
</span></span><span class="line"><span class="cl">        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">val_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
</span></span><span class="line"><span class="cl">        <span class="n">val_correct</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">        <span class="n">val_samples</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">            <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">                <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">                <span class="n">preds</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">val_correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">preds</span> <span class="o">==</span> <span class="n">targets</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">                <span class="n">val_samples</span> <span class="o">+=</span> <span class="n">targets</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">avg_val_loss</span> <span class="o">=</span> <span class="n">val_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">val_accuracy</span> <span class="o">=</span> <span class="n">val_correct</span> <span class="o">/</span> <span class="n">val_samples</span>
</span></span><span class="line"><span class="cl">        <span class="n">tqdm</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;          | Val   Loss: </span><span class="si">{</span><span class="n">avg_val_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> | Acc: </span><span class="si">{</span><span class="n">val_accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Scheduler step</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">scheduler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">try</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">avg_val_loss</span><span class="p">)</span>  <span class="c1"># for ReduceLROnPlateau</span>
</span></span><span class="line"><span class="cl">            <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Early stopping + checkpoint</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">avg_val_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">best_val_loss</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">best_val_loss</span> <span class="o">=</span> <span class="n">avg_val_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">epochs_without_improvement</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;model_state&#34;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;optimizer_state&#34;</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;scheduler_state&#34;</span><span class="p">:</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span> <span class="k">if</span> <span class="n">scheduler</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;best_val_loss&#34;</span><span class="p">:</span> <span class="n">best_val_loss</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;epoch&#34;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="p">},</span> <span class="n">save_path</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">tqdm</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;          | ✅ New best model saved to &#39;</span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&#39;&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">epochs_without_improvement</span> <span class="o">+=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">            <span class="n">tqdm</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;          | No improvement for </span><span class="si">{</span><span class="n">epochs_without_improvement</span><span class="si">}</span><span class="s2"> epoch(s)&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">epochs_without_improvement</span> <span class="o">&gt;=</span> <span class="n">early_stopping_patience</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">tqdm</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;🛑 Early stopping triggered after </span><span class="si">{</span><span class="n">early_stopping_patience</span><span class="si">}</span><span class="s2"> epochs without improvement.&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">break</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Training complete.&#34;</span><span class="p">)</span>      
</span></span></code></pre></div><h3 id="low-rank-factorization">Low-Rank Factorization<a hidden class="anchor" aria-hidden="true" href="#low-rank-factorization">#</a></h3>
<p>Once the baseline model is established, we apply low-rank factorization to compress it. As described earlier, we iterate through all linear and convolutional layers, replacing their weight matrices wherever it results in a meaningful reduction in model size. For linear layers, the weight matrix is factorized into two smaller matrices, which are implemented as two sequential linear layers. For convolutional layers, the weight tensor is first reshaped into a 2D matrix, factorized, and then replaced with two consecutive convolutional layers that approximate the original operation.</p>
<p>It is worth noting that if the reduction in size is not substantial, the latency might slightly increase. This is due to the additional overhead of performing two matrix multiplications instead of the single operation in the original layer. This trade-off is evident in the first few rows of the results table below.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">compress_layer</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.10</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    Compresses a layer using SVD if the compression is beneficial.
</span></span></span><span class="line"><span class="cl"><span class="s2">    Args:
</span></span></span><span class="line"><span class="cl"><span class="s2">        layer (nn.Module): The layer to compress.
</span></span></span><span class="line"><span class="cl"><span class="s2">        epsilon (float): The energy threshold for compression.
</span></span></span><span class="line"><span class="cl"><span class="s2">    Returns:
</span></span></span><span class="line"><span class="cl"><span class="s2">        nn.Module: The compressed layer or the original layer if compression is not beneficial.
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># handle Linear layers</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># get linear layer weight matrix</span>
</span></span><span class="line"><span class="cl">        <span class="n">W</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="c1"># run SVD on flat weight matrix</span>
</span></span><span class="line"><span class="cl">        <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">Vh</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># find rank that capture the asked energy (1-epsilon)</span>
</span></span><span class="line"><span class="cl">        <span class="n">energy</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">S</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">S</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">rank</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">energy</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">epsilon</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># check that factorization actually reduces number of parameters</span>
</span></span><span class="line"><span class="cl">        <span class="n">old_size</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">new_size</span> <span class="o">=</span> <span class="n">rank</span> <span class="o">*</span> <span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">new_size</span> <span class="o">&lt;</span> <span class="n">old_size</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># define low rank factorization from SVD and rank</span>
</span></span><span class="line"><span class="cl">            <span class="n">U_r</span> <span class="o">=</span> <span class="n">U</span><span class="p">[:,</span> <span class="p">:</span><span class="n">rank</span><span class="p">]</span> <span class="o">@</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">S</span><span class="p">[:</span><span class="n">rank</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">            <span class="n">V_r</span> <span class="o">=</span> <span class="n">Vh</span><span class="p">[:</span><span class="n">rank</span><span class="p">,</span> <span class="p">:]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="c1"># define two linear layers to replace the original linear layer</span>
</span></span><span class="line"><span class="cl">            <span class="n">compressed_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">rank</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">compressed_layer</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">V_r</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">compressed_layer</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">U_r</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">compressed_layer</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">compressed_layer</span><span class="p">,</span> <span class="n">old_size</span><span class="p">,</span> <span class="n">new_size</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">    <span class="c1"># handle Conv2d layers</span>
</span></span><span class="line"><span class="cl">    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># get convolution weight 4d matrix, shape: [out_channels, in_channels, kH, kW]</span>
</span></span><span class="line"><span class="cl">        <span class="n">W</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>  
</span></span><span class="line"><span class="cl">        <span class="n">OC</span><span class="p">,</span> <span class="n">IC</span><span class="p">,</span> <span class="n">kH</span><span class="p">,</span> <span class="n">kW</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># reshape to 2d matrix, with shape: [OC, IC*kH*kW]</span>
</span></span><span class="line"><span class="cl">        <span class="n">W_flat</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">OC</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># run SVD on flat weight matrix        </span>
</span></span><span class="line"><span class="cl">        <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">Vh</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">W_flat</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># find rank that capture the asked energy (1-epsilon)</span>
</span></span><span class="line"><span class="cl">        <span class="n">energy</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">S</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">S</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">rank</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">energy</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">epsilon</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># check that factorization actually reduces number of parameters</span>
</span></span><span class="line"><span class="cl">        <span class="n">old_size</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">new_size</span> <span class="o">=</span> <span class="n">rank</span> <span class="o">*</span> <span class="p">(</span><span class="n">IC</span> <span class="o">*</span> <span class="n">kH</span> <span class="o">*</span> <span class="n">kW</span> <span class="o">+</span> <span class="n">OC</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">new_size</span> <span class="o">&lt;</span> <span class="n">old_size</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># define low rank factorization from SVD and rank</span>
</span></span><span class="line"><span class="cl">            <span class="n">U_r</span> <span class="o">=</span> <span class="n">U</span><span class="p">[:,</span> <span class="p">:</span><span class="n">rank</span><span class="p">]</span> <span class="o">@</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">S</span><span class="p">[:</span><span class="n">rank</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">            <span class="n">V_r</span> <span class="o">=</span> <span class="n">Vh</span><span class="p">[:</span><span class="n">rank</span><span class="p">,</span> <span class="p">:]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="c1"># define two convolutional layers to replace the original convolutional layer</span>
</span></span><span class="line"><span class="cl">            <span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">in_channels</span><span class="o">=</span><span class="n">IC</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">out_channels</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">bias</span><span class="o">=</span><span class="kc">False</span>
</span></span><span class="line"><span class="cl">            <span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">in_channels</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">out_channels</span><span class="o">=</span><span class="n">OC</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="n">kH</span><span class="p">,</span> <span class="n">kW</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                <span class="n">stride</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">padding</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">bias</span><span class="o">=</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">V_r</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">IC</span><span class="p">,</span> <span class="n">kH</span><span class="p">,</span> <span class="n">kW</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">conv2</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">U_r</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">OC</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">conv2</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">conv1</span><span class="p">,</span> <span class="n">conv2</span><span class="p">),</span> <span class="n">old_size</span><span class="p">,</span> <span class="n">new_size</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">layer</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>  <span class="c1"># return the original layer if compression is not beneficial</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">compress_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.50</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    Compresses the given model by applying SVD-based compression to Linear and Conv2d layers.
</span></span></span><span class="line"><span class="cl"><span class="s2">    
</span></span></span><span class="line"><span class="cl"><span class="s2">    Args:
</span></span></span><span class="line"><span class="cl"><span class="s2">        model (nn.Module): The model to compress.
</span></span></span><span class="line"><span class="cl"><span class="s2">        epsilon (float): The energy threshold for compression.
</span></span></span><span class="line"><span class="cl"><span class="s2">    
</span></span></span><span class="line"><span class="cl"><span class="s2">    Returns:
</span></span></span><span class="line"><span class="cl"><span class="s2">        nn.Module: The compressed model.
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">   
</span></span><span class="line"><span class="cl">    <span class="n">compressed_model</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>  <span class="c1"># Create a copy of the input model</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">total_old_size</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="n">total_new_size</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">compressed_model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="s1">&#39;.&#39;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>  <span class="c1"># Check if the module has a parent</span>
</span></span><span class="line"><span class="cl">                <span class="n">parent</span><span class="p">,</span> <span class="n">attr</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">rsplit</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">parent_module</span> <span class="o">=</span> <span class="n">compressed_model</span>
</span></span><span class="line"><span class="cl">                <span class="k">for</span> <span class="n">part</span> <span class="ow">in</span> <span class="n">parent</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                    <span class="n">parent_module</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">parent_module</span><span class="p">,</span> <span class="n">part</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">else</span><span class="p">:</span>  <span class="c1"># Handle top-level modules</span>
</span></span><span class="line"><span class="cl">                <span class="n">parent_module</span> <span class="o">=</span> <span class="n">compressed_model</span>
</span></span><span class="line"><span class="cl">                <span class="n">attr</span> <span class="o">=</span> <span class="n">name</span>
</span></span><span class="line"><span class="cl">            <span class="n">new_layer</span><span class="p">,</span> <span class="n">old_size</span><span class="p">,</span> <span class="n">new_size</span> <span class="o">=</span> <span class="n">compress_layer</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">total_old_size</span> <span class="o">+=</span> <span class="n">old_size</span>
</span></span><span class="line"><span class="cl">            <span class="n">total_new_size</span> <span class="o">+=</span> <span class="n">new_size</span>
</span></span><span class="line"><span class="cl">            <span class="nb">setattr</span><span class="p">(</span><span class="n">parent_module</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">new_layer</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">compressed_model</span><span class="p">,</span> <span class="n">total_old_size</span><span class="p">,</span> <span class="n">total_new_size</span>
</span></span></code></pre></div><h3 id="exploring-the-impact-of-epsilon-on-compression-and-performance">Exploring the Impact of Epsilon on Compression and Performance<a hidden class="anchor" aria-hidden="true" href="#exploring-the-impact-of-epsilon-on-compression-and-performance">#</a></h3>
<p>The low-rank factorization method introduces a hyperparameter, epsilon, which determines the proportion of singular values to trim during compression. The code below explores a range of epsilon values to evaluate the trade-offs between compression gains and performance costs. Each compressed model is fine-tuned to maximize its performance after applying the factorization.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Evaluate and print metrics for the original model</span>
</span></span><span class="line"><span class="cl"><span class="n">acc_orig</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">original_model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">example_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">orig_latency_mu</span><span class="p">,</span> <span class="n">orig_latency_std</span> <span class="o">=</span> <span class="n">estimate_latency</span><span class="p">(</span><span class="n">original_model</span><span class="p">,</span> <span class="n">example_input</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">size_orig</span> <span class="o">=</span> <span class="n">get_size</span><span class="p">(</span><span class="n">original_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Original -&gt; acc: </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">acc_orig</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%, latency: </span><span class="si">{</span><span class="n">orig_latency_mu</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">orig_latency_std</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> ms, size: </span><span class="si">{</span><span class="n">size_orig</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">MB&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Iterate over epsilon values</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">epsilon</span> <span class="ow">in</span> <span class="p">[</span><span class="nb">round</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)]:</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">Compressing model with epsilon = </span><span class="si">{</span><span class="n">epsilon</span><span class="si">}</span><span class="s2">...&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># Compress the model</span>
</span></span><span class="line"><span class="cl">    <span class="n">compressed_model</span><span class="p">,</span> <span class="n">total_old_size</span><span class="p">,</span> <span class="n">total_new_size</span> <span class="o">=</span> <span class="n">compress_model</span><span class="p">(</span><span class="n">original_model</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="n">epsilon</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># Evaluate compressed model before fine-tuning</span>
</span></span><span class="line"><span class="cl">    <span class="n">acc_comp</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">compressed_model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Old size: </span><span class="si">{</span><span class="n">total_old_size</span><span class="si">}</span><span class="s2">, New size: </span><span class="si">{</span><span class="n">total_new_size</span><span class="si">}</span><span class="s2">, Parameter count reduction: </span><span class="si">{</span><span class="n">total_old_size</span><span class="o">-</span><span class="n">total_new_size</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Compressed -&gt; acc before tuning: </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">acc_comp</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># Fine-tune the compressed model</span>
</span></span><span class="line"><span class="cl">    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">compressed_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="n">train</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">compressed_model</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">train_loader</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">val_loader</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">optimizer</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">criterion</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">device</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">grad_clip</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">save_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">&#34;compressed_model_epsilon_</span><span class="si">{</span><span class="n">epsilon</span><span class="si">}</span><span class="s2">_best_model.pt&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">early_stopping_patience</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">resume</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># Evaluate compressed model after fine-tuning</span>
</span></span><span class="line"><span class="cl">    <span class="n">acc_tuned_comp</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">compressed_model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">comp_latency_mu</span><span class="p">,</span> <span class="n">comp_latency_std</span> <span class="o">=</span> <span class="n">estimate_latency</span><span class="p">(</span><span class="n">compressed_model</span><span class="p">,</span> <span class="n">example_input</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">size_comp</span> <span class="o">=</span> <span class="n">get_size</span><span class="p">(</span><span class="n">compressed_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># Print metrics for the fine-tuned compressed model</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Compressed -&gt; acc after tuning: </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">acc_tuned_comp</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%, latency: </span><span class="si">{</span><span class="n">comp_latency_mu</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">comp_latency_std</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> ms, size: </span><span class="si">{</span><span class="n">size_comp</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">MB&#34;</span><span class="p">)</span>
</span></span></code></pre></div><h2 id="results">Results<a hidden class="anchor" aria-hidden="true" href="#results">#</a></h2>
<p>As demonstrated in the table below, selecting the optimal compression ratio allowed us to achieve a remarkable <strong>93% reduction in network size</strong>, shrinking it from 94.38 MB to just 6.9 MB. Additionally, we observed a <strong>10% decrease in latency</strong>, all while incurring only a modest <strong>3.5% drop in accuracy</strong>, a highly favorable trade-off for many practical applications.</p>
<table>
  <thead>
      <tr>
          <th>Model</th>
          <th>Accuracy</th>
          <th>Latency (ms)</th>
          <th>Size (MB)</th>
          <th>Size Reduction</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Baseline</td>
          <td>84.64 %</td>
          <td>71.87 ms</td>
          <td>94.38 MB</td>
          <td></td>
      </tr>
      <tr>
          <td>Compressed, eps=0.10</td>
          <td>80.78 %</td>
          <td>84.57 ms</td>
          <td>69.86 MB</td>
          <td>-26 %</td>
      </tr>
      <tr>
          <td>Compressed, eps=0.20</td>
          <td>80.18 %</td>
          <td>78.12 ms</td>
          <td>45.37 MB</td>
          <td>-52 %</td>
      </tr>
      <tr>
          <td>Compressed, eps=0.30</td>
          <td>81.17 %</td>
          <td>70.42 ms</td>
          <td>28.74 MB</td>
          <td>-70 %</td>
      </tr>
      <tr>
          <td>Compressed, eps=0.40</td>
          <td>79.75 %</td>
          <td>68.78 ms</td>
          <td>17.93 MB</td>
          <td>-81 %</td>
      </tr>
      <tr>
          <td>Compressed, eps=0.50</td>
          <td>78.98 %</td>
          <td>65.52 ms</td>
          <td>11.14 MB</td>
          <td>-88 %</td>
      </tr>
      <tr>
          <td><strong>Compressed, eps=0.60</strong></td>
          <td><strong>81.14 %</strong></td>
          <td><strong>64.47 ms</strong></td>
          <td><strong>6.90 MB</strong></td>
          <td><strong>-93 %</strong></td>
      </tr>
      <tr>
          <td>Compressed, eps=0.70</td>
          <td>75.46 %</td>
          <td>64.04 ms</td>
          <td>4.16 MB</td>
          <td>-96 %</td>
      </tr>
      <tr>
          <td>Compressed, eps=0.80</td>
          <td>68.11 %</td>
          <td>63.51 ms</td>
          <td>2.46 MB</td>
          <td>-97 %</td>
      </tr>
      <tr>
          <td>Compressed, eps=0.90</td>
          <td>35.11 %</td>
          <td>66.13 ms</td>
          <td>1.37 MB</td>
          <td>-98 %</td>
      </tr>
  </tbody>
</table>
<hr>
<h2 id="when-it-works-and-when-it-doesnt">When It Works, and When It Doesn’t<a hidden class="anchor" aria-hidden="true" href="#when-it-works-and-when-it-doesnt">#</a></h2>
<p><strong>Low-rank factorization is especially effective when:</strong></p>
<ul>
<li>You’re working with large layers</li>
<li>You can tolerate a small accuracy drop</li>
<li>Deployment constraints favor smaller or faster models</li>
</ul>
<p><strong>It’s less useful when:</strong></p>
<ul>
<li>The network is already compact</li>
<li>Most layers are small or already optimized</li>
<li>You&rsquo;re applying it blindly without analyzing the rank spectrum</li>
</ul>
<p>It’s important to validate the impact layer by layer. Not every matrix benefits from rank reduction.</p>
<hr>
<h2 id="combining-with-other-techniques">Combining with Other Techniques<a hidden class="anchor" aria-hidden="true" href="#combining-with-other-techniques">#</a></h2>
<p>Low-rank factorization plays well with other compression techniques:</p>
<ul>
<li><strong>Pruning</strong>: Prune weights before or after factorization for even more savings.</li>
<li><strong>Quantization</strong>: Factor the model, then apply INT8 quantization to further shrink.</li>
<li><strong>Knowledge Distillation</strong>: Use a distilled model as the starting point for factorization, better performance and fewer parameters.</li>
</ul>
<p>In some settings, stacking these methods leads to additive gains with only minimal engineering overhead.</p>
<hr>
<h2 id="summary">Summary<a hidden class="anchor" aria-hidden="true" href="#summary">#</a></h2>
<p>Low-rank factorization is a matrix decomposition technique that reduces the size of neural networks by approximating weight matrices with fewer parameters. This method is particularly effective for compressing large, redundant layers, achieving significant reductions in model size and latency with minimal accuracy loss when fine-tuned. By leveraging Singular Value Decomposition (SVD), it simplifies implementation and can be combined with other optimization techniques like pruning, quantization, and knowledge distillation for even greater efficiency. This post demonstrated its application on a ResNet50 model, achieving a 93% size reduction and a 10% latency improvement with only a 3.5% accuracy drop, showcasing its practicality for real-world deployments.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://arikpoz.github.io/tags/machine-learning/">Machine-Learning</a></li>
      <li><a href="https://arikpoz.github.io/tags/optimization/">Optimization</a></li>
      <li><a href="https://arikpoz.github.io/tags/deep-learning/">Deep-Learning</a></li>
      <li><a href="https://arikpoz.github.io/tags/low-rank-factorization/">Low-Rank-Factorization</a></li>
      <li><a href="https://arikpoz.github.io/tags/pytorch/">Pytorch</a></li>
      <li><a href="https://arikpoz.github.io/tags/model-compression/">Model-Compression</a></li>
    </ul>
<nav class="paginav">
  <a class="next" href="https://arikpoz.github.io/posts/2025-04-24-knowledge-distillation-in-pytorch-shrinking-neural-networks-the-smart-way/">
    <span class="title">Next »</span>
    <br>
    <span>Knowledge Distillation in PyTorch: Shrinking Neural Networks the Smart Way</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Low-Rank Factorization in PyTorch: Compressing Neural Networks with Linear Algebra on x"
            href="https://x.com/intent/tweet/?text=Low-Rank%20Factorization%20in%20PyTorch%3a%20Compressing%20Neural%20Networks%20with%20Linear%20Algebra&amp;url=https%3a%2f%2farikpoz.github.io%2fposts%2f2025-04-29-low-rank-factorization-in-pytorch-compressing-neural-networks-with-linear-algebra%2f&amp;hashtags=machine-learning%2coptimization%2cdeep-learning%2clow-rank-factorization%2cpytorch%2cmodel-compression">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Low-Rank Factorization in PyTorch: Compressing Neural Networks with Linear Algebra on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2farikpoz.github.io%2fposts%2f2025-04-29-low-rank-factorization-in-pytorch-compressing-neural-networks-with-linear-algebra%2f&amp;title=Low-Rank%20Factorization%20in%20PyTorch%3a%20Compressing%20Neural%20Networks%20with%20Linear%20Algebra&amp;summary=Low-Rank%20Factorization%20in%20PyTorch%3a%20Compressing%20Neural%20Networks%20with%20Linear%20Algebra&amp;source=https%3a%2f%2farikpoz.github.io%2fposts%2f2025-04-29-low-rank-factorization-in-pytorch-compressing-neural-networks-with-linear-algebra%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Low-Rank Factorization in PyTorch: Compressing Neural Networks with Linear Algebra on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2farikpoz.github.io%2fposts%2f2025-04-29-low-rank-factorization-in-pytorch-compressing-neural-networks-with-linear-algebra%2f&title=Low-Rank%20Factorization%20in%20PyTorch%3a%20Compressing%20Neural%20Networks%20with%20Linear%20Algebra">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Low-Rank Factorization in PyTorch: Compressing Neural Networks with Linear Algebra on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2farikpoz.github.io%2fposts%2f2025-04-29-low-rank-factorization-in-pytorch-compressing-neural-networks-with-linear-algebra%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Low-Rank Factorization in PyTorch: Compressing Neural Networks with Linear Algebra on whatsapp"
            href="https://api.whatsapp.com/send?text=Low-Rank%20Factorization%20in%20PyTorch%3a%20Compressing%20Neural%20Networks%20with%20Linear%20Algebra%20-%20https%3a%2f%2farikpoz.github.io%2fposts%2f2025-04-29-low-rank-factorization-in-pytorch-compressing-neural-networks-with-linear-algebra%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Low-Rank Factorization in PyTorch: Compressing Neural Networks with Linear Algebra on telegram"
            href="https://telegram.me/share/url?text=Low-Rank%20Factorization%20in%20PyTorch%3a%20Compressing%20Neural%20Networks%20with%20Linear%20Algebra&amp;url=https%3a%2f%2farikpoz.github.io%2fposts%2f2025-04-29-low-rank-factorization-in-pytorch-compressing-neural-networks-with-linear-algebra%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Low-Rank Factorization in PyTorch: Compressing Neural Networks with Linear Algebra on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Low-Rank%20Factorization%20in%20PyTorch%3a%20Compressing%20Neural%20Networks%20with%20Linear%20Algebra&u=https%3a%2f%2farikpoz.github.io%2fposts%2f2025-04-29-low-rank-factorization-in-pytorch-compressing-neural-networks-with-linear-algebra%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://arikpoz.github.io/">Practical ML</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
