<!DOCTYPE html>
<html lang="en" dir="auto">

<head>
<meta name="google-site-verification" content="W9Zr2fU6GN7Pj5eoP80QHjzCMltqYsT_ut_zg5S8FP8" />

</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://arikpoz.github.io/" accesskey="h" title="Practical ML (Alt + H)">Practical ML</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://arikpoz.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://arikpoz.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://arikpoz.github.io/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      Neural Network Pruning: How to Accelerate Inference with Minimal Accuracy Loss
    </h1>
    <div class="post-meta"><span title='2025-04-10 00:00:00 +0000 UTC'>April 10, 2025</span>&nbsp;·&nbsp;9 min&nbsp;·&nbsp;Arik Poznanski

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#introduction" aria-label="Introduction">Introduction</a></li>
                <li>
                    <a href="#overview-of-pruning" aria-label="Overview of Pruning">Overview of Pruning</a><ul>
                        
                <li>
                    <a href="#pytorch-pruning-api" aria-label="PyTorch Pruning API">PyTorch Pruning API</a></li>
                <li>
                    <a href="#why-use-torch-pruning" aria-label="Why Use Torch-Pruning?">Why Use Torch-Pruning?</a></li></ul>
                </li>
                <li>
                    <a href="#practical-usage-example-pruning-resnet-18-in-pytorch" aria-label="Practical Usage Example: Pruning ResNet-18 in PyTorch">Practical Usage Example: Pruning ResNet-18 in PyTorch</a><ul>
                        
                <li>
                    <a href="#setup" aria-label="Setup">Setup</a></li>
                <li>
                    <a href="#get-cifar-10-train-and-test-sets" aria-label="Get CIFAR-10 Train and Test Sets">Get CIFAR-10 Train and Test Sets</a></li>
                <li>
                    <a href="#adjust-resnet-18-network-for-cifar-10-dataset" aria-label="Adjust ResNet-18 Network for CIFAR-10 Dataset">Adjust ResNet-18 Network for CIFAR-10 Dataset</a></li>
                <li>
                    <a href="#define-train-and-evaluate-functions" aria-label="Define Train and Evaluate Functions">Define Train and Evaluate Functions</a></li>
                <li>
                    <a href="#define-helper-functions-to-measure-latency" aria-label="Define Helper Functions to Measure Latency">Define Helper Functions to Measure Latency</a></li>
                <li>
                    <a href="#train-and-evaluate-the-full-model" aria-label="Train and Evaluate the Full Model">Train and Evaluate the Full Model</a></li>
                <li>
                    <a href="#prune-by-l2-magnitude" aria-label="Prune by L2 Magnitude">Prune by L2 Magnitude</a></li></ul>
                </li>
                <li>
                    <a href="#summary" aria-label="Summary">Summary</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p><img alt="Cartoon of a person in an &ldquo;NN Pruning&rdquo; shirt trimming a large robot labeled &ldquo;Neural Network&rdquo; into a slim, fast robot labeled &ldquo;Pruned Network.&rdquo;" loading="lazy" src="/posts/2025-04-10-neural-network-pruning-how-to-accelerate-inference-with-minimal-accuracy-loss/lead-image.jpg"></p>
<h2 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h2>
<p>In this post, I will demonstrate how to use pruning to <strong>significantly reduce a model&rsquo;s size and latency</strong> while maintaining minimal accuracy loss. In the example, we achieve a <strong>90% reduction in model size</strong> and <strong>5.5x faster inference time</strong>, all while preserving the same level of accuracy.</p>
<p>We will begin with a brief explanation of what pruning is and why it is important. Then, I’ll provide a hands-on demonstration of applying pruning to a PyTorch model.</p>
<h2 id="overview-of-pruning">Overview of Pruning<a hidden class="anchor" aria-hidden="true" href="#overview-of-pruning">#</a></h2>
<p>Neural network pruning involves removing less important weights, channels, or neurons from a neural network to make it smaller and faster. The goal is to reduce computational costs (such as latency and memory usage) without significantly affecting model accuracy.</p>
<p>Deep neural networks often contain a lot of redundancy. This redundancy arises because models are typically overparameterized to ensure high accuracy and generalization. During training, many parameters become co-dependent or have little impact on the final output. For example, multiple neurons may learn similar features, or certain filters may remain underutilized. This redundancy makes models robust but also bloated. Pruning helps streamline these models by eliminating parts that contribute the least to the output, resulting in a more efficient network that is easier to deploy on edge devices or in latency-sensitive applications.</p>
<p>There are two main types of pruning:</p>
<ul>
<li>
<p><strong>Unstructured Pruning</strong>: Removes individual weights regardless of their position. While it can achieve high sparsity, it often requires specialized hardware or libraries to fully utilize the sparsity. Zeroing out individual weights typically does not improve latency because standard deep learning libraries use dense matrix multiplication regardless of how many weights are zeroed out. To benefit from sparsity, the model must be converted into a sparse format, which is often not well-supported by commodity hardware. In fact, these sparse representations can sometimes be slower than dense operations due to less optimized memory access patterns and lack of hardware acceleration. As a result, unstructured pruning offers theoretical compression but not always practical speedups unless carefully integrated into the deployment pipeline.</p>
</li>
<li>
<p><strong>Structured Pruning</strong>: Removes entire filters, channels, or layers, leading to real improvements in inference speed on standard hardware. Unlike unstructured pruning, which retains the original dense structure and thus doesn’t alter compute patterns, structured pruning directly reduces the dimensionality of tensors and layers. This means fewer floating-point operations (FLOPs) and less memory access, as the actual matrices involved in convolutions and linear operations are physically smaller. As a result, inference is faster and more efficient on standard hardware using optimized dense kernels, with no need for specialized sparse computation support.</p>
</li>
</ul>
<h3 id="pytorch-pruning-api">PyTorch Pruning API<a hidden class="anchor" aria-hidden="true" href="#pytorch-pruning-api">#</a></h3>
<p>PyTorch provides a built-in pruning utility under <code>torch.nn.utils.prune</code>. This API supports both unstructured pruning (zeroing individual weights by magnitude or custom metrics) and structured pruning (removing entire channels or neurons). The <a href="https://medium.com/towards-data-science/how-to-prune-neural-networks-with-pytorch-ebef60316b91#:~%5C:text=PyTorch%20offers%20a%20built,or%20by%20a%20custom%20metric">PyTorch pruning tutorial</a> offers a solid introduction using iterative magnitude pruning. However, it is important to note that the PyTorch pruning API does not result in real inference speedups out-of-the-box. This is because it primarily focuses on zeroing out weights rather than removing them. For unstructured pruning, it does not convert the model to a sparse representation, which is necessary to leverage computational gains. For structured pruning, it does not automatically modify the architecture to remove entire channels or filters, which means the computational graph remains unchanged.</p>
<p>That said, the PyTorch pruning API is a flexible and useful tool for experimenting with pruning strategies. It provides a simple interface to apply custom pruning criteria, evaluate sparsity effects, and implement iterative pruning and retraining loops. It is especially helpful for research and prototyping where exact hardware efficiency is less critical than functional model behavior.</p>
<h3 id="why-use-torch-pruning">Why Use Torch-Pruning?<a hidden class="anchor" aria-hidden="true" href="#why-use-torch-pruning">#</a></h3>
<p>Structured pruning isn’t trivial. Removing a channel in one layer often requires modifying downstream layers. Structured pruning often involves complex inter-layer dependencies. For example, if you prune an output channel from a convolutional layer, any layer that consumes its output, such as a batch normalization layer or subsequent convolution, must also be updated to match the new shape. Managing these changes across many layers can be error-prone and tedious when done manually. Torch-Pruning solves this by introducing a graph-based algorithm called <a href="https://github.com/VainF/Torch-Pruning#dependency-graph">DepGraph</a>, which automatically analyzes the model&rsquo;s computation graph, identifies dependencies, and organizes pruning into safe and consistent execution plans.</p>
<hr>
<h2 id="practical-usage-example-pruning-resnet-18-in-pytorch">Practical Usage Example: Pruning ResNet-18 in PyTorch<a hidden class="anchor" aria-hidden="true" href="#practical-usage-example-pruning-resnet-18-in-pytorch">#</a></h2>
<p>Let’s walk through pruning a ResNet-18 model step-by-step using <code>torch-pruning</code>. We&rsquo;ll do this in Google Colab, so you can follow along easily. This example is adapted from the official README of Torch-Pruning.</p>
<p><a href="https://colab.research.google.com/drive/1ovh52r4z-lypwRdaCrw9PfCLW6RZI2Sn?usp=sharing"><strong>Run this code in Google Colab</strong></a> to try it yourself.</p>
<h3 id="setup">Setup<a hidden class="anchor" aria-hidden="true" href="#setup">#</a></h3>
<p>First, install the required library:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">torch</span><span class="o">-</span><span class="n">pruning</span>
</span></span></code></pre></div><p>Then, define the required imports:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">os</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">time</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">copy</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span><span class="p">,</span> <span class="n">models</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch_pruning</span> <span class="k">as</span> <span class="nn">tp</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&#34;cuda&#34;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&#34;cpu&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">device</span><span class="si">=}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></div><h3 id="get-cifar-10-train-and-test-sets">Get CIFAR-10 Train and Test Sets<a hidden class="anchor" aria-hidden="true" href="#get-cifar-10-train-and-test-sets">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,))</span>
</span></span><span class="line"><span class="cl"><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s2">&#34;./data&#34;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s2">&#34;./data&#34;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></div><h3 id="adjust-resnet-18-network-for-cifar-10-dataset">Adjust ResNet-18 Network for CIFAR-10 Dataset<a hidden class="anchor" aria-hidden="true" href="#adjust-resnet-18-network-for-cifar-10-dataset">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">get_resnet18_for_cifar10</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">maxpool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">full_model</span> <span class="o">=</span> <span class="n">get_resnet18_for_cifar10</span><span class="p">()</span>
</span></span></code></pre></div><h3 id="define-train-and-evaluate-functions">Define Train and Evaluate Functions<a hidden class="anchor" aria-hidden="true" href="#define-train-and-evaluate-functions">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loader</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="s2">&#34;model.pth&#34;</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">save_path</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Model already trained. Loading from </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">save_path</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: loss=</span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">save_path</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="ow">not</span> <span class="n">silent</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Training complete. Model saved to </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">correct</span> <span class="o">=</span> <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">preds</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">total</span> <span class="o">+=</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
</span></span></code></pre></div><h3 id="define-helper-functions-to-measure-latency">Define Helper Functions to Measure Latency<a hidden class="anchor" aria-hidden="true" href="#define-helper-functions-to-measure-latency">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Timer</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">use_cuda</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_cuda</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">starter</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Event</span><span class="p">(</span><span class="n">enable_timing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">ender</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Event</span><span class="p">(</span><span class="n">enable_timing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">start</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_cuda</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">starter</span><span class="o">.</span><span class="n">record</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">stop</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_cuda</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">ender</span><span class="o">.</span><span class="n">record</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">starter</span><span class="o">.</span><span class="n">elapsed_time</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ender</span><span class="p">)</span>  <span class="c1"># ms</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_time</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span>  <span class="c1"># ms</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">estimate_latency</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">example_inputs</span><span class="p">,</span> <span class="n">repetitions</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">timer</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">timings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">repetitions</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Warm-up</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">example_inputs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">rep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">repetitions</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">timer</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">example_inputs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">elapsed</span> <span class="o">=</span> <span class="n">timer</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">timings</span><span class="p">[</span><span class="n">rep</span><span class="p">]</span> <span class="o">=</span> <span class="n">elapsed</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">timings</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">timings</span><span class="p">)</span>
</span></span></code></pre></div><h3 id="train-and-evaluate-the-full-model">Train and Evaluate the Full Model<a hidden class="anchor" aria-hidden="true" href="#train-and-evaluate-the-full-model">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">train</span><span class="p">(</span><span class="n">full_model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="s2">&#34;full_model.pth&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">accuracy_full</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">full_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">example_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">macs</span><span class="p">,</span> <span class="n">parameters</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">count_ops_and_params</span><span class="p">(</span><span class="n">full_model</span><span class="p">,</span> <span class="n">example_input</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">latency_mu</span><span class="p">,</span> <span class="n">latency_std</span> <span class="o">=</span> <span class="n">estimate_latency</span><span class="p">(</span><span class="n">full_model</span><span class="p">,</span> <span class="n">example_input</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;[full model] </span><span class="se">\t\t</span><span class="s2">MACs: </span><span class="si">{</span><span class="n">macs</span><span class="o">/</span><span class="mf">1e9</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> G, </span><span class="se">\t</span><span class="s2">Parameters: </span><span class="si">{</span><span class="n">parameters</span><span class="o">/</span><span class="mf">1e6</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> M, </span><span class="se">\t</span><span class="s2">Latency: </span><span class="si">{</span><span class="n">latency_mu</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">latency_std</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> ms </span><span class="se">\t</span><span class="s2">Accuracy: </span><span class="si">{</span><span class="n">accuracy_full</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&#34;</span><span class="p">)</span>
</span></span></code></pre></div><p>To save you some time, here are the results for the fully trained model:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-s" data-lang="s"><span class="line"><span class="cl"><span class="n">[full</span> <span class="n">model]</span> 		<span class="n">MACs</span><span class="o">:</span> <span class="m">0.56</span> <span class="n">G</span><span class="p">,</span> 	<span class="n">Parameters</span><span class="o">:</span> <span class="m">11.17</span> <span class="n">M</span><span class="p">,</span> 	<span class="n">Latency</span><span class="o">:</span> <span class="m">16.52</span> ± <span class="m">0.03</span> <span class="n">ms</span> 	<span class="n">Accuracy</span><span class="o">:</span> <span class="m">76.85</span>%
</span></span></code></pre></div><h3 id="prune-by-l2-magnitude">Prune by L2 Magnitude<a hidden class="anchor" aria-hidden="true" href="#prune-by-l2-magnitude">#</a></h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Clone full model before pruning</span>
</span></span><span class="line"><span class="cl"><span class="n">pruned_model</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">full_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">pruned_model</span> <span class="o">=</span> <span class="n">pruned_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Set which layers to skip pruning. Important to keep the final classifier layer</span>
</span></span><span class="line"><span class="cl"><span class="n">ignored_layers</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">pruned_model</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">)</span> <span class="ow">and</span> <span class="n">m</span><span class="o">.</span><span class="n">out_features</span> <span class="o">==</span> <span class="mi">10</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">ignored_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Iterative pruning</span>
</span></span><span class="line"><span class="cl"><span class="n">iterative_steps</span> <span class="o">=</span> <span class="mi">20</span>
</span></span><span class="line"><span class="cl"><span class="n">pruner</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">pruner</span><span class="o">.</span><span class="n">MagnitudePruner</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">=</span><span class="n">pruned_model</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">example_inputs</span><span class="o">=</span><span class="n">example_input</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">importance</span><span class="o">=</span><span class="n">tp</span><span class="o">.</span><span class="n">importance</span><span class="o">.</span><span class="n">MagnitudeImportance</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">pruning_ratio</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">iterative_steps</span><span class="o">=</span><span class="n">iterative_steps</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">ignored_layers</span><span class="o">=</span><span class="n">ignored_layers</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">round_to</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">for</span> <span class="nb">iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iterative_steps</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Prune</span>
</span></span><span class="line"><span class="cl">    <span class="n">pruner</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Evaluate after pruning</span>
</span></span><span class="line"><span class="cl">    <span class="n">acc_before</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">pruned_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Fine-tune pruned model</span>
</span></span><span class="line"><span class="cl">    <span class="n">train</span><span class="p">(</span><span class="n">pruned_model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">&#34;pruned_model_</span><span class="si">{</span><span class="nb">iter</span><span class="si">}</span><span class="s2">.pth&#34;</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Evaluate after fine-tuning</span>
</span></span><span class="line"><span class="cl">    <span class="n">acc_after</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">pruned_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Count MACs and parameters</span>
</span></span><span class="line"><span class="cl">    <span class="n">macs</span><span class="p">,</span> <span class="n">parameters</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">count_ops_and_params</span><span class="p">(</span><span class="n">pruned_model</span><span class="p">,</span> <span class="n">example_input</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">latency_mu</span><span class="p">,</span> <span class="n">latency_std</span> <span class="o">=</span> <span class="n">estimate_latency</span><span class="p">(</span><span class="n">pruned_model</span><span class="p">,</span> <span class="n">example_input</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">current_pruning_ratio</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">iterative_steps</span> <span class="o">*</span> <span class="p">(</span><span class="nb">iter</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;[pruned model] </span><span class="se">\t</span><span class="s2">Pruning ratio: </span><span class="si">{</span><span class="n">current_pruning_ratio</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, </span><span class="se">\t</span><span class="s2">MACs: </span><span class="si">{</span><span class="n">macs</span><span class="o">/</span><span class="mf">1e9</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> G, </span><span class="se">\t</span><span class="s2">Parameters: </span><span class="si">{</span><span class="n">parameters</span><span class="o">/</span><span class="mf">1e6</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> M, </span><span class="se">\t</span><span class="s2">Latency: </span><span class="si">{</span><span class="n">latency_mu</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">latency_std</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> ms </span><span class="se">\t</span><span class="s2">Accuracy pruned: </span><span class="si">{</span><span class="n">acc_before</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%</span><span class="se">\t</span><span class="s2">Finetuned: </span><span class="si">{</span><span class="n">acc_after</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&#34;</span><span class="p">)</span>
</span></span></code></pre></div><p>The pruning results show the model&rsquo;s accuracy immediately after pruning and again after fine-tuning the smaller, pruned model. While accuracy initially drops following pruning, it recovers significantly after just one epoch of fine-tuning.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-s" data-lang="s"><span class="line"><span class="cl"><span class="n">[pruned</span> <span class="n">model]</span> 	<span class="n">Pruning</span> <span class="n">ratio</span><span class="o">:</span> <span class="m">0.05</span><span class="p">,</span> 	<span class="n">MACs</span><span class="o">:</span> <span class="m">0.49</span> <span class="n">G</span><span class="p">,</span> 	<span class="n">Parameters</span><span class="o">:</span> <span class="m">10.03</span> <span class="n">M</span><span class="p">,</span> 	<span class="n">Latency</span><span class="o">:</span> <span class="m">17.64</span> ± <span class="m">0.04</span> <span class="n">ms</span> 	<span class="n">Accuracy</span> <span class="n">pruned</span><span class="o">:</span> <span class="m">63.60</span><span class="o">%	Finetuned: 72.17%</span>
</span></span><span class="line"><span class="cl"><span class="n">[pruned</span> <span class="n">model]</span> 	<span class="n">Pruning</span> <span class="n">ratio</span><span class="o">:</span> <span class="m">0.10</span><span class="p">,</span> 	<span class="n">MACs</span><span class="o">:</span> <span class="m">0.44</span> <span class="n">G</span><span class="p">,</span> 	<span class="n">Parameters</span><span class="o">:</span> <span class="m">9.00</span> <span class="n">M</span><span class="p">,</span> 	<span class="n">Latency</span><span class="o">:</span> <span class="m">16.12</span> ± <span class="m">0.04</span> <span class="n">ms</span> 	<span class="n">Accuracy</span> <span class="n">pruned</span><span class="o">:</span> <span class="m">44.51</span><span class="o">%	Finetuned: 76.51%</span>
</span></span><span class="line"><span class="cl"><span class="n">[pruned</span> <span class="n">model]</span> 	<span class="n">Pruning</span> <span class="n">ratio</span><span class="o">:</span> <span class="m">0.15</span><span class="p">,</span> 	<span class="n">MACs</span><span class="o">:</span> <span class="m">0.40</span> <span class="n">G</span><span class="p">,</span> 	<span class="n">Parameters</span><span class="o">:</span> <span class="m">8.01</span> <span class="n">M</span><span class="p">,</span> 	<span class="n">Latency</span><span class="o">:</span> <span class="m">16.40</span> ± <span class="m">0.04</span> <span class="n">ms</span> 	<span class="n">Accuracy</span> <span class="n">pruned</span><span class="o">:</span> <span class="m">66.98</span><span class="o">%	Finetuned: 75.18%</span>
</span></span><span class="line"><span class="cl"><span class="n">[pruned</span> <span class="n">model]</span> 	<span class="n">Pruning</span> <span class="n">ratio</span><span class="o">:</span> <span class="m">0.20</span><span class="p">,</span> 	<span class="n">MACs</span><span class="o">:</span> <span class="m">0.35</span> <span class="n">G</span><span class="p">,</span> 	<span class="n">Parameters</span><span class="o">:</span> <span class="m">7.09</span> <span class="n">M</span><span class="p">,</span> 	<span class="n">Latency</span><span class="o">:</span> <span class="m">16.33</span> ± <span class="m">0.04</span> <span class="n">ms</span> 	<span class="n">Accuracy</span> <span class="n">pruned</span><span class="o">:</span> <span class="m">51.83</span><span class="o">%	Finetuned: 74.64%</span>
</span></span><span class="line"><span class="cl"><span class="n">[pruned</span> <span class="n">model]</span> 	<span class="n">Pruning</span> <span class="n">ratio</span><span class="o">:</span> <span class="m">0.25</span><span class="p">,</span> 	<span class="n">MACs</span><span class="o">:</span> <span class="m">0.31</span> <span class="n">G</span><span class="p">,</span> 	<span class="n">Parameters</span><span class="o">:</span> <span class="m">6.29</span> <span class="n">M</span><span class="p">,</span> 	<span class="n">Latency</span><span class="o">:</span> <span class="m">14.40</span> ± <span class="m">0.05</span> <span class="n">ms</span> 	<span class="n">Accuracy</span> <span class="n">pruned</span><span class="o">:</span> <span class="m">63.51</span><span class="o">%	Finetuned: 76.73%</span>
</span></span><span class="line"><span class="cl"><span class="n">[pruned</span> <span class="n">model]</span> 	<span class="n">Pruning</span> <span class="n">ratio</span><span class="o">:</span> <span class="m">0.30</span><span class="p">,</span> 	<span class="n">MACs</span><span class="o">:</span> <span class="m">0.27</span> <span class="n">G</span><span class="p">,</span> 	<span class="n">Parameters</span><span class="o">:</span> <span class="m">5.44</span> <span class="n">M</span><span class="p">,</span> 	<span class="n">Latency</span><span class="o">:</span> <span class="m">14.07</span> ± <span class="m">0.03</span> <span class="n">ms</span> 	<span class="n">Accuracy</span> <span class="n">pruned</span><span class="o">:</span> <span class="m">49.36</span><span class="o">%	Finetuned: 74.64%</span>
</span></span><span class="line"><span class="cl"><span class="n">[pruned</span> <span class="n">model]</span> 	<span class="n">Pruning</span> <span class="n">ratio</span><span class="o">:</span> <span class="m">0.35</span><span class="p">,</span> 	<span class="n">MACs</span><span class="o">:</span> <span class="m">0.23</span> <span class="n">G</span><span class="p">,</span> 	<span class="n">Parameters</span><span class="o">:</span> <span class="m">4.69</span> <span class="n">M</span><span class="p">,</span> 	<span class="n">Latency</span><span class="o">:</span> <span class="m">12.27</span> ± <span class="m">0.03</span> <span class="n">ms</span> 	<span class="n">Accuracy</span> <span class="n">pruned</span><span class="o">:</span> <span class="m">58.74</span><span class="o">%	Finetuned: 77.56%</span>
</span></span><span class="line"><span class="cl"><span class="n">[pruned</span> <span class="n">model]</span> 	<span class="n">Pruning</span> <span class="n">ratio</span><span class="o">:</span> <span class="m">0.40</span><span class="p">,</span> 	<span class="n">MACs</span><span class="o">:</span> <span class="m">0.20</span> <span class="n">G</span><span class="p">,</span> 	<span class="n">Parameters</span><span class="o">:</span> <span class="m">3.98</span> <span class="n">M</span><span class="p">,</span> 	<span class="n">Latency</span><span class="o">:</span> <span class="m">12.28</span> ± <span class="m">0.03</span> <span class="n">ms</span> 	<span class="n">Accuracy</span> <span class="n">pruned</span><span class="o">:</span> <span class="m">63.98</span><span class="o">%	Finetuned: 78.29%</span>
</span></span><span class="line"><span class="cl"><span class="n">[pruned</span> <span class="n">model]</span> 	<span class="n">Pruning</span> <span class="n">ratio</span><span class="o">:</span> <span class="m">0.45</span><span class="p">,</span> 	<span class="n">MACs</span><span class="o">:</span> <span class="m">0.16</span> <span class="n">G</span><span class="p">,</span> 	<span class="n">Parameters</span><span class="o">:</span> <span class="m">3.34</span> <span class="n">M</span><span class="p">,</span> 	<span class="n">Latency</span><span class="o">:</span> <span class="m">11.41</span> ± <span class="m">0.02</span> <span class="n">ms</span> 	<span class="n">Accuracy</span> <span class="n">pruned</span><span class="o">:</span> <span class="m">45.66</span><span class="o">%	Finetuned: 78.58%</span>
</span></span><span class="line"><span class="cl"><span class="n">[pruned</span> <span class="n">model]</span> 	<span class="n">Pruning</span> <span class="n">ratio</span><span class="o">:</span> <span class="m">0.50</span><span class="p">,</span> 	<span class="n">MACs</span><span class="o">:</span> <span class="m">0.14</span> <span class="n">G</span><span class="p">,</span> 	<span class="n">Parameters</span><span class="o">:</span> <span class="m">2.80</span> <span class="n">M</span><span class="p">,</span> 	<span class="n">Latency</span><span class="o">:</span> <span class="m">7.06</span> ± <span class="m">0.03</span> <span class="n">ms</span> 	<span class="n">Accuracy</span> <span class="n">pruned</span><span class="o">:</span> <span class="m">49.91</span><span class="o">%	Finetuned: 72.77%</span>
</span></span><span class="line"><span class="cl"><span class="n">[pruned</span> <span class="n">model]</span> 	<span class="n">Pruning</span> <span class="n">ratio</span><span class="o">:</span> <span class="m">0.55</span><span class="p">,</span> 	<span class="n">MACs</span><span class="o">:</span> <span class="m">0.11</span> <span class="n">G</span><span class="p">,</span> 	<span class="n">Parameters</span><span class="o">:</span> <span class="m">2.24</span> <span class="n">M</span><span class="p">,</span> 	<span class="n">Latency</span><span class="o">:</span> <span class="m">6.82</span> ± <span class="m">0.05</span> <span class="n">ms</span> 	<span class="n">Accuracy</span> <span class="n">pruned</span><span class="o">:</span> <span class="m">38.72</span><span class="o">%	Finetuned: 76.13%</span>
</span></span><span class="line"><span class="cl"><span class="n">[pruned</span> <span class="n">model]</span> 	<span class="n">Pruning</span> <span class="n">ratio</span><span class="o">:</span> <span class="m">0.60</span><span class="p">,</span> 	<span class="n">MACs</span><span class="o">:</span> <span class="m">0.09</span> <span class="n">G</span><span class="p">,</span> 	<span class="n">Parameters</span><span class="o">:</span> <span class="m">1.77</span> <span class="n">M</span><span class="p">,</span> 	<span class="n">Latency</span><span class="o">:</span> <span class="m">5.96</span> ± <span class="m">0.05</span> <span class="n">ms</span> 	<span class="n">Accuracy</span> <span class="n">pruned</span><span class="o">:</span> <span class="m">42.84</span><span class="o">%	Finetuned: 79.09%</span>
</span></span><span class="line"><span class="cl"><span class="n">[pruned</span> <span class="n">model]</span> 	<span class="n">Pruning</span> <span class="n">ratio</span><span class="o">:</span> <span class="m">0.65</span><span class="p">,</span> 	<span class="n">MACs</span><span class="o">:</span> <span class="m">0.07</span> <span class="n">G</span><span class="p">,</span> 	<span class="n">Parameters</span><span class="o">:</span> <span class="m">1.34</span> <span class="n">M</span><span class="p">,</span> 	<span class="n">Latency</span><span class="o">:</span> <span class="m">4.88</span> ± <span class="m">0.09</span> <span class="n">ms</span> 	<span class="n">Accuracy</span> <span class="n">pruned</span><span class="o">:</span> <span class="m">33.88</span><span class="o">%	Finetuned: 75.54%</span>
</span></span><span class="line"><span class="cl"><span class="n">[pruned</span> <span class="n">model]</span> 	<span class="n">Pruning</span> <span class="n">ratio</span><span class="o">:</span> <span class="m">0.70</span><span class="p">,</span> 	<span class="n">MACs</span><span class="o">:</span> <span class="m">0.05</span> <span class="n">G</span><span class="p">,</span> 	<span class="n">Parameters</span><span class="o">:</span> <span class="m">0.99</span> <span class="n">M</span><span class="p">,</span> 	<span class="n">Latency</span><span class="o">:</span> <span class="m">4.17</span> ± <span class="m">0.01</span> <span class="n">ms</span> 	<span class="n">Accuracy</span> <span class="n">pruned</span><span class="o">:</span> <span class="m">22.50</span><span class="o">%	Finetuned: 75.60%</span>
</span></span><span class="line"><span class="cl"><span class="n">[pruned</span> <span class="n">model]</span> 	<span class="n">Pruning</span> <span class="n">ratio</span><span class="o">:</span> <span class="m">0.75</span><span class="p">,</span> 	<span class="n">MACs</span><span class="o">:</span> <span class="m">0.04</span> <span class="n">G</span><span class="p">,</span> 	<span class="n">Parameters</span><span class="o">:</span> <span class="m">0.70</span> <span class="n">M</span><span class="p">,</span> 	<span class="n">Latency</span><span class="o">:</span> <span class="m">2.96</span> ± <span class="m">0.08</span> <span class="n">ms</span> 	<span class="n">Accuracy</span> <span class="n">pruned</span><span class="o">:</span> <span class="m">34.23</span><span class="o">%	Finetuned: 78.91%</span>
</span></span><span class="line"><span class="cl"><span class="n">[pruned</span> <span class="n">model]</span> 	<span class="n">Pruning</span> <span class="n">ratio</span><span class="o">:</span> <span class="m">0.80</span><span class="p">,</span> 	<span class="n">MACs</span><span class="o">:</span> <span class="m">0.02</span> <span class="n">G</span><span class="p">,</span> 	<span class="n">Parameters</span><span class="o">:</span> <span class="m">0.44</span> <span class="n">M</span><span class="p">,</span> 	<span class="n">Latency</span><span class="o">:</span> <span class="m">2.70</span> ± <span class="m">0.02</span> <span class="n">ms</span> 	<span class="n">Accuracy</span> <span class="n">pruned</span><span class="o">:</span> <span class="m">15.91</span><span class="o">%	Finetuned: 75.55%</span>
</span></span><span class="line"><span class="cl"><span class="n">[pruned</span> <span class="n">model]</span> 	<span class="n">Pruning</span> <span class="n">ratio</span><span class="o">:</span> <span class="m">0.85</span><span class="p">,</span> 	<span class="n">MACs</span><span class="o">:</span> <span class="m">0.01</span> <span class="n">G</span><span class="p">,</span> 	<span class="n">Parameters</span><span class="o">:</span> <span class="m">0.25</span> <span class="n">M</span><span class="p">,</span> 	<span class="n">Latency</span><span class="o">:</span> <span class="m">2.69</span> ± <span class="m">0.04</span> <span class="n">ms</span> 	<span class="n">Accuracy</span> <span class="n">pruned</span><span class="o">:</span> <span class="m">14.16</span><span class="o">%	Finetuned: 75.01%</span>
</span></span><span class="line"><span class="cl"><span class="n">[pruned</span> <span class="n">model]</span> 	<span class="n">Pruning</span> <span class="n">ratio</span><span class="o">:</span> <span class="m">0.90</span><span class="p">,</span> 	<span class="n">MACs</span><span class="o">:</span> <span class="m">0.01</span> <span class="n">G</span><span class="p">,</span> 	<span class="n">Parameters</span><span class="o">:</span> <span class="m">0.11</span> <span class="n">M</span><span class="p">,</span> 	<span class="n">Latency</span><span class="o">:</span> <span class="m">2.63</span> ± <span class="m">0.01</span> <span class="n">ms</span> 	<span class="n">Accuracy</span> <span class="n">pruned</span><span class="o">:</span> <span class="m">10.00</span><span class="o">%	Finetuned: 68.87%</span>
</span></span><span class="line"><span class="cl"><span class="n">[pruned</span> <span class="n">model]</span> 	<span class="n">Pruning</span> <span class="n">ratio</span><span class="o">:</span> <span class="m">0.95</span><span class="p">,</span> 	<span class="n">MACs</span><span class="o">:</span> <span class="m">0.00</span> <span class="n">G</span><span class="p">,</span> 	<span class="n">Parameters</span><span class="o">:</span> <span class="m">0.03</span> <span class="n">M</span><span class="p">,</span> 	<span class="n">Latency</span><span class="o">:</span> <span class="m">2.59</span> ± <span class="m">0.02</span> <span class="n">ms</span> 	<span class="n">Accuracy</span> <span class="n">pruned</span><span class="o">:</span> <span class="m">10.00</span><span class="o">%	Finetuned: 53.36%</span>
</span></span><span class="line"><span class="cl"><span class="n">[pruned</span> <span class="n">model]</span> 	<span class="n">Pruning</span> <span class="n">ratio</span><span class="o">:</span> <span class="m">1.00</span><span class="p">,</span> 	<span class="n">MACs</span><span class="o">:</span> <span class="m">0.00</span> <span class="n">G</span><span class="p">,</span> 	<span class="n">Parameters</span><span class="o">:</span> <span class="m">0.03</span> <span class="n">M</span><span class="p">,</span> 	<span class="n">Latency</span><span class="o">:</span> <span class="m">2.57</span> ± <span class="m">0.01</span> <span class="n">ms</span> 	<span class="n">Accuracy</span> <span class="n">pruned</span><span class="o">:</span> <span class="m">53.36</span><span class="o">%	Finetuned: 54.91%</span>
</span></span></code></pre></div><p>Note that one of the final models achives same accuracy (even higher, 78.91%) while having <strong>15x less parameters</strong> (0.7M vs. 11.17M), and is <strong>5.5x faster than original</strong> (2.96 ms vs. 16.52 ms).</p>
<h2 id="summary">Summary<a hidden class="anchor" aria-hidden="true" href="#summary">#</a></h2>
<p>Pruning is a powerful technique to make deep networks lighter and faster. In this blog post, we:</p>
<ul>
<li>Explored what pruning is and why it matters</li>
<li>Compared the native PyTorch pruning API with Torch-Pruning</li>
<li>Used <code>torch-pruning</code> to prune a ResNet-18 model in PyTorch</li>
<li>Evaluated model size, inference latency, and top-1 prediction accuracy using CIFAR-10 data</li>
</ul>
<p>By applying structured pruning, you can make your models more efficient with minimal impact on performance, a valuable step in any model optimization workflow.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
<nav class="paginav">
  <a class="next" href="https://arikpoz.github.io/posts/2025-04-07-fast-image-loading-with-nvidia-nvimagecodec/">
    <span class="title">Next »</span>
    <br>
    <span>Fast Image Loading with NVIDIA nvImageCodec</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Neural Network Pruning: How to Accelerate Inference with Minimal Accuracy Loss on x"
            href="https://x.com/intent/tweet/?text=Neural%20Network%20Pruning%3a%20How%20to%20Accelerate%20Inference%20with%20Minimal%20Accuracy%20Loss&amp;url=https%3a%2f%2farikpoz.github.io%2fposts%2f2025-04-10-neural-network-pruning-how-to-accelerate-inference-with-minimal-accuracy-loss%2f&amp;hashtags=">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Neural Network Pruning: How to Accelerate Inference with Minimal Accuracy Loss on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2farikpoz.github.io%2fposts%2f2025-04-10-neural-network-pruning-how-to-accelerate-inference-with-minimal-accuracy-loss%2f&amp;title=Neural%20Network%20Pruning%3a%20How%20to%20Accelerate%20Inference%20with%20Minimal%20Accuracy%20Loss&amp;summary=Neural%20Network%20Pruning%3a%20How%20to%20Accelerate%20Inference%20with%20Minimal%20Accuracy%20Loss&amp;source=https%3a%2f%2farikpoz.github.io%2fposts%2f2025-04-10-neural-network-pruning-how-to-accelerate-inference-with-minimal-accuracy-loss%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Neural Network Pruning: How to Accelerate Inference with Minimal Accuracy Loss on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2farikpoz.github.io%2fposts%2f2025-04-10-neural-network-pruning-how-to-accelerate-inference-with-minimal-accuracy-loss%2f&title=Neural%20Network%20Pruning%3a%20How%20to%20Accelerate%20Inference%20with%20Minimal%20Accuracy%20Loss">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Neural Network Pruning: How to Accelerate Inference with Minimal Accuracy Loss on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2farikpoz.github.io%2fposts%2f2025-04-10-neural-network-pruning-how-to-accelerate-inference-with-minimal-accuracy-loss%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Neural Network Pruning: How to Accelerate Inference with Minimal Accuracy Loss on whatsapp"
            href="https://api.whatsapp.com/send?text=Neural%20Network%20Pruning%3a%20How%20to%20Accelerate%20Inference%20with%20Minimal%20Accuracy%20Loss%20-%20https%3a%2f%2farikpoz.github.io%2fposts%2f2025-04-10-neural-network-pruning-how-to-accelerate-inference-with-minimal-accuracy-loss%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Neural Network Pruning: How to Accelerate Inference with Minimal Accuracy Loss on telegram"
            href="https://telegram.me/share/url?text=Neural%20Network%20Pruning%3a%20How%20to%20Accelerate%20Inference%20with%20Minimal%20Accuracy%20Loss&amp;url=https%3a%2f%2farikpoz.github.io%2fposts%2f2025-04-10-neural-network-pruning-how-to-accelerate-inference-with-minimal-accuracy-loss%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Neural Network Pruning: How to Accelerate Inference with Minimal Accuracy Loss on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Neural%20Network%20Pruning%3a%20How%20to%20Accelerate%20Inference%20with%20Minimal%20Accuracy%20Loss&u=https%3a%2f%2farikpoz.github.io%2fposts%2f2025-04-10-neural-network-pruning-how-to-accelerate-inference-with-minimal-accuracy-loss%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://arikpoz.github.io/">Practical ML</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
